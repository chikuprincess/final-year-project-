# -*- coding: utf-8 -*-
"""final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qm8odEho5SRcE_8yYgLfiz5Si_2CS54n
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import os
import pandas as pd

# Path to dataset base folder
base_dir = "/content/drive/MyDrive/model project/herlev_item"

# Mapping of folders to labels
label_map = {'negative': 0, 'positive': 1}

# Collect image paths and labels
image_paths = []
labels = []

# Walk through each class directory
for class_name, label in label_map.items():
    class_folder = os.path.join(base_dir, class_name)

    for root, dirs, files in os.walk(class_folder):  # <- walks recursively
        for filename in files:
            if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
                file_path = os.path.join(root, filename)
                image_paths.append(file_path)
                labels.append(label)

# Build DataFrame
df = pd.DataFrame({
    'image_path': image_paths,
    'label': labels
})

# Save CSV
csv_path = os.path.join(base_dir, "sv_labels.csv")
df.to_csv(csv_path, index=False)

print(f"âœ… CSV created with {len(df)} entries at: {csv_path}")

# 2. Import libraries
import pandas as pd
import os
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import tensorflow as tf
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# 3. Load your dataset
df = pd.read_excel('/content/drive/MyDrive/model project/multimodal.xlsx')

# Count positive and negative cases
print("Class distribution:")
print(df['label'].value_counts())

# 4. Preprocessing text
# Drop non-feature columns
text_features = df.drop(columns=['image_path', 'label'])

# Normalize numeric data (recommended)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
text_data = scaler.fit_transform(text_features)


# 5. Preprocessing images
def process_image(img_path):
    full_path = os.path.join('/content/drive/MyDrive/model project/herlev_item', img_path)
    image = load_img(full_path, target_size=(224, 224))
    image = img_to_array(image) / 255.0
    return image

images = np.array([process_image(p) for p in df['image_path']])

# 6. Prepare data
X_text = text_data
X_image = images
y = df['label'].values

X_train_img, X_test_img, X_train_txt, X_test_txt, y_train, y_test = train_test_split(
    X_image, X_text, y, test_size=0.2, random_state=42)

# 7. Define multimodal model
def build_model(num_text_features):
    # Image input
    image_input = Input(shape=(224, 224, 3))
    base_model = EfficientNetB0(include_top=False, input_tensor=image_input, weights='imagenet')
    x = GlobalAveragePooling2D()(base_model.output)

    # Tabular input
    text_input = Input(shape=(num_text_features,))
    text_features = Dense(128, activation='relu')(text_input)

    # Combine
    combined = Concatenate()([x, text_features])
    x = Dense(64, activation='relu')(combined)
    output = Dense(1, activation='sigmoid')(x)

    model = Model(inputs=[image_input, text_input], outputs=output)
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Rebuild model using actual feature count
model = build_model(text_data.shape[1])
model.summary()


# 8. Train the model
model.fit([X_train_img, X_train_txt], y_train, epochs=5, batch_size=16, validation_split=0.1)

# 9. Evaluate the model
# 9. Evaluate the model
y_pred = (model.predict([X_test_img, X_test_txt]) > 0.5).astype("int32")

# Print accuracy and classification report
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

# Calculate and print the number of positive and negative predictions
positive_cases = np.sum(y_pred == 1)
negative_cases = np.sum(y_pred == 0)

print(f"Predicted Positive Cases: {positive_cases}")
print(f"Predicted Negative Cases: {negative_cases}")

print(df.columns)

pip install torch torchvision pandas scikit-learn pillow

import os
import pandas as pd
import numpy as np
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import models, transforms


# 1. Load and preprocess data
df = pd.read_excel('/content/drive/MyDrive/model project/multimodal.xlsx')  # Use .csv if needed
df = df.dropna()

image_paths = df['image_path'].values
labels = df['label'].values
tabular_data = df.drop(['image_path', 'label'], axis=1).values

scaler = StandardScaler()
tabular_data = scaler.fit_transform(tabular_data)

train_img, val_img, train_tab, val_tab, train_labels, val_labels = train_test_split(
    image_paths, tabular_data, labels, test_size=0.2, random_state=42
)

# 2. Dataset Class
class MultimodalDataset(Dataset):
    def __init__(self, image_paths, tabular_data, labels, transform=None):
        self.image_paths = image_paths
        self.tabular_data = torch.tensor(tabular_data, dtype=torch.float32)
        self.labels = torch.tensor(labels, dtype=torch.long)
        self.transform = transform or transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        image = Image.open(img_path).convert('RGB')
        image = self.transform(image)
        tabular = self.tabular_data[idx]
        label = self.labels[idx]
        return image, tabular, label

# 3. DataLoaders
train_dataset = MultimodalDataset(train_img, train_tab, train_labels)
val_dataset = MultimodalDataset(val_img, val_tab, val_labels)

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16)

# 4. Model Definition
class MultimodalModel(nn.Module):
    def __init__(self, tabular_input_dim):
        super(MultimodalModel, self).__init__()
        self.cnn = models.resnet18(pretrained=True)
        self.cnn.fc = nn.Linear(self.cnn.fc.in_features, 128)

        self.tabular_net = nn.Sequential(
            nn.Linear(tabular_input_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 32)
        )

        self.classifier = nn.Sequential(
            nn.Linear(128 + 32, 64),
            nn.ReLU(),
            nn.Linear(64, 2)
        )

    def forward(self, image, tabular):
        img_feat = self.cnn(image)
        tab_feat = self.tabular_net(tabular)
        combined = torch.cat((img_feat, tab_feat), dim=1)
        out = self.classifier(combined)
        return out

# 5. Training Setup
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = MultimodalModel(tabular_input_dim=train_tab.shape[1]).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

# 6. Training Loop
epochs = 10
for epoch in range(epochs):
    model.train()
    total_loss = 0
    for images, tabular, labels in train_loader:
        images, tabular, labels = images.to(device), tabular.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images, tabular)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    print(f"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}")

# 7. Evaluation
model.eval()
all_preds, all_labels = [], []
with torch.no_grad():
    for images, tabular, labels in val_loader:
        images, tabular = images.to(device), tabular.to(device)
        outputs = model(images, tabular)
        preds = torch.argmax(outputs, dim=1).cpu().numpy()
        all_preds.extend(preds)
        all_labels.extend(labels.numpy())

print("\nFinal Evaluation:")
print("Accuracy:", accuracy_score(all_labels, all_preds))
print(classification_report(all_labels, all_preds))

